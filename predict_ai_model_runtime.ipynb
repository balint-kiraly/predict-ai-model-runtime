{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 58266,
          "databundleVersionId": 6641124,
          "sourceType": "competition"
        },
        {
          "sourceId": 144043388,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 144045966,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 144045983,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 31153,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "predict_ai_model_runtime",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "hl_xjqJiFm6T"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "predict_ai_model_runtime_path = kagglehub.competition_download('predict-ai-model-runtime')\n",
        "samihaija_tpugraphsv1_layout_data_py_path = kagglehub.utility_script_install('samihaija/tpugraphsv1-layout-data-py')\n",
        "samihaija_tpugraphsv1_implicit_py_path = kagglehub.utility_script_install('samihaija/tpugraphsv1-implicit-py')\n",
        "samihaija_tpugraphsv1_tile_data_py_path = kagglehub.utility_script_install('samihaija/tpugraphsv1-tile-data-py')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "5pdqdSpNFm6V"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/balint-kiraly/predict-ai-model-runtime.git\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ],
      "metadata": {
        "id": "fV4WaZ6-Fm6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-14T22:47:24.257538Z",
          "iopub.execute_input": "2025-12-14T22:47:24.257907Z",
          "iopub.status.idle": "2025-12-14T22:47:29.583363Z",
          "shell.execute_reply.started": "2025-12-14T22:47:24.257886Z",
          "shell.execute_reply": "2025-12-14T22:47:29.582696Z"
        },
        "id": "PHYxIuMaFm6Y",
        "outputId": "e51082b5-7b52-47b0-dbc3-911708e8bff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting torch-geometric\n  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.12.15)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.9.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (7.1.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.0.9)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.5.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.8.3)\nRequirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-geometric) (2024.2.0)\nDownloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.7.0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "print(\"PyTorch has version {}\".format(torch.__version__))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-14T22:47:29.584882Z",
          "iopub.execute_input": "2025-12-14T22:47:29.585143Z",
          "iopub.status.idle": "2025-12-14T22:47:33.025217Z",
          "shell.execute_reply.started": "2025-12-14T22:47:29.585122Z",
          "shell.execute_reply": "2025-12-14T22:47:33.024465Z"
        },
        "id": "dI-ZVV5iFm6Z",
        "outputId": "289307e8-32a2-4470-e431-17f5040de29c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "PyTorch has version 2.6.0+cu124\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-2.6.0+cu124.html"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-14T22:47:33.026041Z",
          "iopub.execute_input": "2025-12-14T22:47:33.02649Z",
          "iopub.status.idle": "2025-12-14T22:47:37.159404Z",
          "shell.execute_reply.started": "2025-12-14T22:47:33.026464Z",
          "shell.execute_reply": "2025-12-14T22:47:37.158715Z"
        },
        "id": "pvasu9SuFm6a",
        "outputId": "58641be8-2ad0-4e34-ff7f-4d9b520705a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Looking in links: https://pytorch-geometric.com/whl/torch-2.6.0+cu124.html\nCollecting torch-scatter\n  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-scatter\nSuccessfully installed torch-scatter-2.1.2+pt26cu124\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-14T22:47:37.161552Z",
          "iopub.execute_input": "2025-12-14T22:47:37.161788Z",
          "iopub.status.idle": "2025-12-14T22:47:43.957544Z",
          "shell.execute_reply.started": "2025-12-14T22:47:37.161769Z",
          "shell.execute_reply": "2025-12-14T22:47:43.9569Z"
        },
        "id": "64PA3Bg1Fm6c",
        "outputId": "89b7408c-fcec-4d6a-cb63-25232a3ba06f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Using device: cuda\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_df(directory):\n",
        "    splits = [\"train\", \"valid\", \"test\"]\n",
        "    dfs = dict()\n",
        "\n",
        "    for split in splits:\n",
        "        path = os.path.join(directory, split)\n",
        "        if not os.path.exists(path):\n",
        "            continue\n",
        "\n",
        "        files = os.listdir(path)\n",
        "        list_df = []\n",
        "\n",
        "        for file in files:\n",
        "            d = dict(np.load(os.path.join(path,file)))\n",
        "            d['file'] = file\n",
        "            list_df.append(d)\n",
        "        dfs[split] = pd.DataFrame.from_dict(list_df)\n",
        "    return dfs\n",
        "\n",
        "tile_xla = load_df(\"/kaggle/input/predict-ai-model-runtime/npz_all/npz/tile/xla/\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-14T22:47:43.958255Z",
          "iopub.execute_input": "2025-12-14T22:47:43.958714Z",
          "iopub.status.idle": "2025-12-14T22:48:39.700011Z",
          "shell.execute_reply.started": "2025-12-14T22:47:43.958695Z",
          "shell.execute_reply": "2025-12-14T22:48:39.69939Z"
        },
        "id": "igvFCCBTFm6c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class TileDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        # Features\n",
        "        config_feat = torch.tensor(row['config_feat'].astype(np.float32))\n",
        "        node_feat = torch.tensor(row['node_feat'].astype(np.float32))\n",
        "\n",
        "        node_opcode = torch.tensor(row['node_opcode'].astype(np.int64))\n",
        "        edge_index = torch.tensor(np.swapaxes(row['edge_index'],0,1).astype(np.int64))\n",
        "\n",
        "        # Target: Normalized Runtime\n",
        "        target = (row['config_runtime'] / row['config_runtime_normalizers']).astype(np.float32)\n",
        "\n",
        "        # Simple MinMax scaling\n",
        "        target = (target - min(target)) / (max(target) - min(target))\n",
        "        target = torch.tensor(target)\n",
        "\n",
        "        return config_feat, node_feat, node_opcode, edge_index, target"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-14T22:48:39.70072Z",
          "iopub.execute_input": "2025-12-14T22:48:39.700925Z",
          "iopub.status.idle": "2025-12-14T22:48:39.706477Z",
          "shell.execute_reply.started": "2025-12-14T22:48:39.700909Z",
          "shell.execute_reply": "2025-12-14T22:48:39.705918Z"
        },
        "id": "dU99YnOzFm6e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def pairwise_ranking_loss(preds, targets, margin=0.1):\n",
        "    \"\"\"\n",
        "    Computes pairwise ranking loss.\n",
        "    If target[i] < target[j] (i is faster), we want pred[i] < pred[j] (i has lower score).\n",
        "    \"\"\"\n",
        "    # Generate all pairs (broadcasting)\n",
        "    # preds: (N, 1) -> (N, N) diffs\n",
        "    # View as (N, 1) to ensure broadcasting works correctly if input is flat\n",
        "    if preds.dim() == 1:\n",
        "        preds = preds.view(-1, 1)\n",
        "\n",
        "    pred_diff = preds - preds.t()\n",
        "\n",
        "    # targets: (N, ) -> (N, N) diffs\n",
        "    target_diff = targets.unsqueeze(1) - targets.unsqueeze(0)\n",
        "\n",
        "    # Determine correct ordering\n",
        "    # S_ij = 1 if i should be faster (lower runtime) than j\n",
        "    # S_ij = -1 if i should be slower than j\n",
        "    # S_ij = 0 if they are equal\n",
        "    S = torch.sign(target_diff)\n",
        "\n",
        "    # Compute hinge loss\n",
        "    # If S_ij = 1 (target_i > target_j, i is SLOWER), we want pred_i > pred_j\n",
        "    # So pred_diff (pred_i - pred_j) should be positive.\n",
        "    # Loss = max(0, -S * pred_diff + margin)\n",
        "\n",
        "    # We only care where targets are different\n",
        "    mask = (S != 0)\n",
        "\n",
        "    # S contains signs of (target_i - target_j).\n",
        "    # If target_i > target_j (i is slower), S=1. We want pred_i > pred_j.\n",
        "    # ideally (pred_i - pred_j) > 0.\n",
        "    # if (pred_i - pred_j) < 0 (wrong order), we penalize.\n",
        "\n",
        "    loss = torch.nn.functional.relu(margin - S[mask] * pred_diff[mask])\n",
        "    return loss.mean()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-14T22:48:39.707188Z",
          "iopub.execute_input": "2025-12-14T22:48:39.707409Z",
          "iopub.status.idle": "2025-12-14T22:48:39.725759Z",
          "shell.execute_reply.started": "2025-12-14T22:48:39.707394Z",
          "shell.execute_reply": "2025-12-14T22:48:39.725041Z"
        },
        "id": "vrAHRz-LFm6h"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, graph_feats, hidden_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        op_embedding_dim = 32\n",
        "        self.embedding = torch.nn.Embedding(120, op_embedding_dim)\n",
        "\n",
        "        # Input channels: 140 node feats + 32 embedding\n",
        "        in_channels = op_embedding_dim + 140\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "\n",
        "        # Layer 1\n",
        "        self.convs.append(SAGEConv(in_channels, hidden_channels[0]))\n",
        "\n",
        "        # Subsequent layers\n",
        "        for i in range(len(hidden_channels)-1):\n",
        "            self.convs.append(SAGEConv(hidden_channels[i], hidden_channels[i+1]))\n",
        "\n",
        "        last_dim = hidden_channels[-1]\n",
        "\n",
        "        # Graph processing final layer\n",
        "        self.conv_final = SAGEConv(last_dim, graph_feats)\n",
        "\n",
        "        # Dense layers for final prediction\n",
        "        # Input: graph_feats + 24 config features\n",
        "        self.dense = torch.nn.Sequential(\n",
        "            nn.Linear(graph_feats + 24, 128),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cfg: Tensor, x_feat: Tensor, x_op: Tensor, edge_index: Tensor) -> Tensor:\n",
        "\n",
        "        # Embed OpCodes and concatenate with Node Features\n",
        "        x = torch.cat([x_feat, self.embedding(x_op)], dim=1)\n",
        "\n",
        "        # Pass through Graph Convolutions\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, edge_index).relu()\n",
        "\n",
        "        # Final convolutional layer\n",
        "        x = self.conv_final(x, edge_index).relu()\n",
        "        # ---------------------------------------------\n",
        "\n",
        "        # Get Graph Embedding\n",
        "        x_graph = torch.mean(x, dim=0)\n",
        "\n",
        "        # Concatenate Graph Embedding with Config Features\n",
        "        x_graph_repeated = x_graph.repeat((len(x_cfg), 1))\n",
        "\n",
        "        combined = torch.cat([x_cfg, x_graph_repeated], dim=1)\n",
        "\n",
        "        # Predict Score\n",
        "        out = self.dense(combined)\n",
        "\n",
        "        return torch.flatten(out)\n",
        "\n",
        "model = Model(hidden_channels=[64, 128, 64], graph_feats=128, hidden_dim=64).to(device)\n",
        "print(\"Model corrected and re-created.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-14T22:48:39.727266Z",
          "iopub.execute_input": "2025-12-14T22:48:39.727497Z",
          "iopub.status.idle": "2025-12-14T22:48:39.952656Z",
          "shell.execute_reply.started": "2025-12-14T22:48:39.727481Z",
          "shell.execute_reply": "2025-12-14T22:48:39.95198Z"
        },
        "id": "CffOZyFvFm6h",
        "outputId": "64f67eaa-64e1-4855-e8cb-1a2362c93ea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Model corrected and re-created.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TileDataset(tile_xla[\"train\"])\n",
        "criterion_mae = torch.nn.L1Loss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "epochs = 5\n",
        "# Limit the memory usage -> otherwise crashes\n",
        "MAX_RANKING_SAMPLES = 2000\n",
        "\n",
        "model.train()\n",
        "print(\"Starting training with memory optimization...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    pbar = tqdm(range(len(dataset)))\n",
        "    loss_sum = 0\n",
        "    n = 0\n",
        "\n",
        "    for i in pbar:\n",
        "        cfg_ft, nd_ft, nd_op, ind, target = dataset[i]\n",
        "\n",
        "        cfg_ft = cfg_ft.to(device)\n",
        "        nd_ft = nd_ft.to(device)\n",
        "        nd_op = nd_op.to(device)\n",
        "        ind = ind.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        out = model(cfg_ft, nd_ft, nd_op, ind)\n",
        "\n",
        "        # If there are too many configs, pick a random subset to compare\n",
        "        if len(target) > MAX_RANKING_SAMPLES:\n",
        "            perm = torch.randperm(len(target))\n",
        "            idx = perm[:MAX_RANKING_SAMPLES]\n",
        "            loss_rank = pairwise_ranking_loss(out[idx], target[idx])\n",
        "        else:\n",
        "            loss_rank = pairwise_ranking_loss(out, target)\n",
        "\n",
        "        loss_reg = criterion_mae(out, target)\n",
        "\n",
        "        loss = loss_rank + 0.1 * loss_reg\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_sum += loss.item()\n",
        "        n += 1\n",
        "        pbar.set_description(f'Epoch {epoch+1}/{epochs} | Loss: {(loss_sum/n):.4f}')\n",
        "\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-14T22:48:39.953429Z",
          "iopub.execute_input": "2025-12-14T22:48:39.953663Z",
          "iopub.status.idle": "2025-12-14T22:54:45.644833Z",
          "shell.execute_reply.started": "2025-12-14T22:48:39.953646Z",
          "shell.execute_reply": "2025-12-14T22:54:45.64427Z"
        },
        "id": "iJHLdAz9Fm6i",
        "outputId": "7b8ff66b-f16c-45bb-bdee-c50089f465e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Starting training with memory optimization...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 1/5 | Loss: 0.8161: 100%|██████████| 5709/5709 [01:13<00:00, 77.23it/s] \nEpoch 2/5 | Loss: 0.0617: 100%|██████████| 5709/5709 [01:13<00:00, 78.18it/s]\nEpoch 3/5 | Loss: 0.0633: 100%|██████████| 5709/5709 [01:13<00:00, 78.15it/s]\nEpoch 4/5 | Loss: 0.0581: 100%|██████████| 5709/5709 [01:12<00:00, 78.39it/s]\nEpoch 5/5 | Loss: 0.0803: 100%|██████████| 5709/5709 [01:12<00:00, 78.38it/s]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = TileDataset(tile_xla[\"valid\"])\n",
        "tile_xla_predictions = []\n",
        "model.eval()\n",
        "\n",
        "print(\"Validating...\")\n",
        "pbar = tqdm(range(len(val_dataset)))\n",
        "for i in pbar:\n",
        "    cfg_ft, nd_ft, nd_op, ind, target = val_dataset[i]\n",
        "    cfg_ft = cfg_ft.to(device)\n",
        "    nd_ft = nd_ft.to(device)\n",
        "    nd_op = nd_op.to(device)\n",
        "    ind = ind.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model(cfg_ft, nd_ft, nd_op, ind)\n",
        "\n",
        "    # We want the indices of the configurations with the lowest predicted runtime\n",
        "    # argsort sorts ascending, so [:5] gives indices of lowest 5\n",
        "    tile_xla_predictions.append(np.argsort(out.cpu().numpy())[:5])\n",
        "\n",
        "def score_tile(predictions, df):\n",
        "    score = 0\n",
        "    for i in range(len(df)):\n",
        "        # Calculate score based on how close our best prediction was to the actual best\n",
        "        predbest = min(df.iloc[i]['config_runtime'][predictions[i]])\n",
        "        best = min(df.iloc[i]['config_runtime'])\n",
        "        score += 2 - predbest/best\n",
        "    score /= len(df)\n",
        "    return score\n",
        "\n",
        "val_score = score_tile(tile_xla_predictions, tile_xla[\"valid\"])\n",
        "print(f\"Validation Score: {val_score}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-14T22:54:45.646613Z",
          "iopub.execute_input": "2025-12-14T22:54:45.6468Z",
          "iopub.status.idle": "2025-12-14T22:54:47.562702Z",
          "shell.execute_reply.started": "2025-12-14T22:54:45.646786Z",
          "shell.execute_reply": "2025-12-14T22:54:47.562105Z"
        },
        "id": "Ip7bOdUeFm6j",
        "outputId": "b95a0fb2-00b9-421b-882e-44d4053abf37"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Validating...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 676/676 [00:01<00:00, 372.06it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Score: 0.948936010479559\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = TileDataset(tile_xla[\"test\"])\n",
        "test_predictions = []\n",
        "model.eval()\n",
        "\n",
        "print(\"Running inference on test set...\")\n",
        "pbar = tqdm(range(len(test_dataset)))\n",
        "for i in pbar:\n",
        "    cfg_ft, nd_ft, nd_op, ind, target = test_dataset[i]\n",
        "    cfg_ft = cfg_ft.to(device)\n",
        "    nd_ft = nd_ft.to(device)\n",
        "    nd_op = nd_op.to(device)\n",
        "    ind = ind.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model(cfg_ft, nd_ft, nd_op, ind)\n",
        "\n",
        "    test_predictions.append(np.argsort(out.cpu().numpy())[:5])\n",
        "\n",
        "# Create Submission CSV\n",
        "sub = pd.read_csv('/kaggle/input/predict-ai-model-runtime/sample_submission.csv')\n",
        "for i, filename in enumerate(tile_xla[\"test\"]['file'].values):\n",
        "    id = 'tile:xla:' + filename[:-4]\n",
        "    sub.loc[sub.ID == id, 'TopConfigs'] = ';'.join(test_predictions[i].astype(str))\n",
        "\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print(\"submission.csv created successfully.\")\n",
        "sub.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-14T22:54:47.563389Z",
          "iopub.execute_input": "2025-12-14T22:54:47.563648Z",
          "iopub.status.idle": "2025-12-14T22:54:50.068333Z",
          "shell.execute_reply.started": "2025-12-14T22:54:47.563622Z",
          "shell.execute_reply": "2025-12-14T22:54:50.067637Z"
        },
        "id": "Vp8r6IY2Fm6j",
        "outputId": "a9831c1f-335f-48fb-e308-81a1f50afd2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Running inference on test set...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  0%|          | 0/844 [00:00<?, ?it/s]/tmp/ipykernel_38/2198928961.py:22: RuntimeWarning: invalid value encountered in divide\n  target = (target - min(target)) / (max(target) - min(target))\n100%|██████████| 844/844 [00:02<00:00, 380.83it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "submission.csv created successfully.\n",
          "output_type": "stream"
        },
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                          ID               TopConfigs\n0  tile:xla:d6f5f54247bd1e58a10b9e7062c636ab                0;1;2;3;4\n1  tile:xla:e3a655daa38e34ec240df959b650ac16     528;667;888;1094;396\n2  tile:xla:f8c2c1a1098b2a361c26df668b286c87         84;40;204;12;189\n3  tile:xla:4dd1716853ed46ee4e7d09ede1732de8  3939;1015;7320;903;8910\n4  tile:xla:d0a69155b6340748c36724e4bfc34be3      576;159;236;650;151",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>TopConfigs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tile:xla:d6f5f54247bd1e58a10b9e7062c636ab</td>\n      <td>0;1;2;3;4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tile:xla:e3a655daa38e34ec240df959b650ac16</td>\n      <td>528;667;888;1094;396</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tile:xla:f8c2c1a1098b2a361c26df668b286c87</td>\n      <td>84;40;204;12;189</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tile:xla:4dd1716853ed46ee4e7d09ede1732de8</td>\n      <td>3939;1015;7320;903;8910</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tile:xla:d0a69155b6340748c36724e4bfc34be3</td>\n      <td>576;159;236;650;151</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    }
  ]
}